{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-fLi9N5F9TY"
      },
      "source": [
        "# RNN Based molucule generation\n",
        "\n",
        "Laurent Cetinsoy\n",
        "\n",
        "In this hands-on we want to generate molecule formulas for denovo-drug discovery.\n",
        "\n",
        "For that we need to use Generative models. Generative models are models which goes beyond classification or simple regression : they are able to generate data that look like previously seens dataset.\n",
        "\n",
        "There exists a lot of models :\n",
        "\n",
        "- Bayesian models like graphical models\n",
        "- Recurrent models (for sequence generation like texte)\n",
        "- Variational auto encoders\n",
        "- Generative adversarial models\n",
        "- Flow and diffusion models\n",
        "\n",
        "\n",
        "In the hands-on we will start by  trainning a character based RNN to generate smile molecules\n",
        "\n",
        "\n",
        "We want to feed smile representations of molecules to an RNN.\n",
        "The basic idea is we will train it to predict the next smile token of a molecule given the previous one.\n",
        "\n",
        "For instance for the following molecule \"CC(=O)NC1=CC=C(O)C=C1\" will may give to the model\n",
        "\n",
        "X = \"CC(=O)N\"\n",
        "y = C\n",
        "\n",
        "and ask the RNN to learn to predict y given X\n",
        "\n",
        "Like a standard language model !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyiF_PC-F9TZ"
      },
      "source": [
        "## RNN Language model\n",
        "\n",
        "\n",
        "A language model is a model which predict the next token of a sequence given the previous ones :\n",
        "\n",
        "$ P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n",
        "\n",
        "\n",
        "This model can be learned with a Recurrent neural network\n",
        "\n",
        "$ y = P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p}) = RNN_{\\theta} (X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n",
        "\n",
        "\n",
        "In order to train such model you need a corpus of data.\n",
        "\n",
        "\n",
        "\n",
        "There are two main ways to do that : Word level model or character level model\n",
        "\n",
        "For character level models, an interesting resource is : http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1wFjoG4F9TZ"
      },
      "source": [
        "Explain briefly what is the difference between word based language model and character based language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNdgc9BhF9TZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNrv4u-2F9TZ"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q5agrnuF9TZ"
      },
      "source": [
        "Dowload the following dataset : https://github.com/joeymach/Leveraging-VAE-to-generate-molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S_2XtEXMF9TZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34m9Tp6jF9Ta"
      },
      "source": [
        "Import pandas and load the first 1000 lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5vjteeIYF9Ta"
      },
      "outputs": [],
      "source": [
        "data_path = '250k_smiles.csv'\n",
        "df = pd.read_csv(data_path).head(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX82FcjBF9Ta"
      },
      "source": [
        "Display the first rows of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FskblqIKF9Ta",
        "outputId": "a91623b2-f512-4cd2-86fa-19c2861580a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              smiles     logP       qed  \\\n",
              "0          CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n  5.05060  0.702012   \n",
              "1     C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\\n  3.11370  0.928975   \n",
              "2  N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...  4.96778  0.599682   \n",
              "3  CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...  4.00022  0.690944   \n",
              "4  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...  3.60956  0.789027   \n",
              "\n",
              "        SAS  \n",
              "0  2.084095  \n",
              "1  3.432004  \n",
              "2  2.470633  \n",
              "3  2.822753  \n",
              "4  4.035182  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48f5acf4-bb1a-4443-a7e5-e56b8cec2a46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>logP</th>\n",
              "      <th>qed</th>\n",
              "      <th>SAS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n</td>\n",
              "      <td>5.05060</td>\n",
              "      <td>0.702012</td>\n",
              "      <td>2.084095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\\n</td>\n",
              "      <td>3.11370</td>\n",
              "      <td>0.928975</td>\n",
              "      <td>3.432004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...</td>\n",
              "      <td>4.96778</td>\n",
              "      <td>0.599682</td>\n",
              "      <td>2.470633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...</td>\n",
              "      <td>4.00022</td>\n",
              "      <td>0.690944</td>\n",
              "      <td>2.822753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...</td>\n",
              "      <td>3.60956</td>\n",
              "      <td>0.789027</td>\n",
              "      <td>4.035182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48f5acf4-bb1a-4443-a7e5-e56b8cec2a46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48f5acf4-bb1a-4443-a7e5-e56b8cec2a46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48f5acf4-bb1a-4443-a7e5-e56b8cec2a46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0597eb55-0587-4a15-8e5d-326364c5851c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0597eb55-0587-4a15-8e5d-326364c5851c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0597eb55-0587-4a15-8e5d-326364c5851c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"N#Cc1ccc(OC2CCC(NC(=O)c3ccc[nH]3)CC2)nc1\\n\",\n          \"Cc1ccc(F)c(C[NH+]2CCC(C(=O)NC(C)C)CC2)c1\\n\",\n          \"CCc1ccc(/C=C(\\\\C#N)C(N)=O)s1\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4736462511891064,\n        \"min\": -2.9468,\n        \"max\": 6.15252,\n        \"num_unique_values\": 995,\n        \"samples\": [\n          3.01694,\n          4.3819,\n          2.7385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14056536453573196,\n        \"min\": 0.159707353629,\n        \"max\": 0.944291701836,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.907163732834,\n          0.874209941904,\n          0.608641728564\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SAS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8013742587844209,\n        \"min\": 1.6177473510713265,\n        \"max\": 5.968905818013142,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          2.567054813157532,\n          3.4253751854189067,\n          2.6732769419674405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHEd8UosF9Ta"
      },
      "source": [
        "## Processing the data\n",
        "\n",
        "We need to do the following things :\n",
        "\n",
        "- convert smile tokens to numbers\n",
        "- build  smile token sequences and corresponding labels pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTnl69ZzF9Ta"
      },
      "source": [
        "Compute the biggest smile molecule size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVgn3EpZF9Ta",
        "outputId": "ad922c74-1c0d-49f2-8630-ce8b2571f8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The bigest molecule size in smiles is: 106\n"
          ]
        }
      ],
      "source": [
        "longest_length = df['smiles'].str.len().max()\n",
        "print(f\"The bigest molecule size in smiles is: {longest_length}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r40-M-exF9Ta"
      },
      "source": [
        "\n",
        "Code a function **unic_characters(string)** which return the unic characters in a string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1n0Qf73F9Ta",
        "outputId": "f40b3322-f43d-4109-a488-457de7cb1c2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['b', 'j', 'o', 'r', 's']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def unic_characters(text):\n",
        "    \"\"\"Renvoie une liste triée des caractères uniques dans un texte donné.\"\"\"\n",
        "    return sorted(set(text))\n",
        "#test\n",
        "unic_characters(\"bbbbbooooojjjjjrsssss\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k07XnZEF9Ta"
      },
      "source": [
        "Concatenate all smile string of the pandas dataframe and use **unic_characters** to get the unic_characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s18t5DqiF9Ta",
        "outputId": "4ecf032c-9231-419f-d6d3-218a9565c375"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '#',\n",
              " '(',\n",
              " ')',\n",
              " '+',\n",
              " '-',\n",
              " '/',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '=',\n",
              " '@',\n",
              " 'B',\n",
              " 'C',\n",
              " 'F',\n",
              " 'H',\n",
              " 'I',\n",
              " 'N',\n",
              " 'O',\n",
              " 'S',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " 'c',\n",
              " 'l',\n",
              " 'n',\n",
              " 'o',\n",
              " 'r',\n",
              " 's']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "all_molecules = ''.join(df['smiles'].tolist())\n",
        "distinct_chars = unic_characters(all_molecules)\n",
        "distinct_chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOpqC80PF9Ta"
      },
      "source": [
        "Code a function **map_char_to_int(unic_chars)** which returns a dictionnary where each char is assigned an int value.\n",
        "Add a character to specify the end of the molecule (like \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RZtfkJDuF9Ta"
      },
      "outputs": [],
      "source": [
        "\n",
        "def map_char_to_int(unic_chars):\n",
        "    \"\"\"\n",
        "    Maps unique characters to integer values.\n",
        "\n",
        "    Args:\n",
        "      unic_chars: A list of unique characters.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary where keys are characters and values are integer mappings.\n",
        "    \"\"\"\n",
        "    char_to_int = dict((c, i) for i, c in enumerate(unic_chars))\n",
        "    char_to_int['\\n'] = len(char_to_int)  # Add end-of-molecule character\n",
        "    return char_to_int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mub7Gk9fF9Ta"
      },
      "source": [
        "Code a function map_int_to_char(unic_chars) which returns the reverse mapping.\n",
        "\n",
        "If you want you can merge both functions in a class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_KaU-UVpF9Ta"
      },
      "outputs": [],
      "source": [
        "\n",
        "def map_int_to_char(unic_chars):\n",
        "    \"\"\"\n",
        "    Maps integer values back to unique characters.\n",
        "\n",
        "    Args:\n",
        "      unic_chars: A list of unique characters.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary where keys are integer mappings and values are characters.\n",
        "    \"\"\"\n",
        "    int_to_char = dict((i, c) for i, c in enumerate(unic_chars))\n",
        "    int_to_char[len(int_to_char)] = '\\n'  # Add end-of-molecule character mapping\n",
        "    return int_to_char"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each smile molecule add the ending token to it"
      ],
      "metadata": {
        "id": "lMYcBol6IBNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0a1vTX-wF9Tb"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['smiles'] = df['smiles'] + '\\n'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['smiles'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "DTjczl4GIL8F",
        "outputId": "3cc6a092-63dd-47c2-e133-748e7e7d219b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n\\n\n",
              "1     C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\\n\\n\n",
              "2    N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...\n",
              "3    CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...\n",
              "4    N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...\n",
              "Name: smiles, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaiYFU-wF9Tb"
      },
      "source": [
        "## Building the dataset\n",
        "\n",
        "Now we will create the dataset so that it has the good share for our Keras LSTM model\n",
        "\n",
        "Remember Keras recurrent models expect a 3D array with shapes (n_examples, seq_len, n_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBEY9h0JF9Tb"
      },
      "source": [
        "What will be n_features in our case ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o9S2cJnF9Tb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEhxmGiLF9Tb"
      },
      "source": [
        "*Code* a function **build_X_and_y(string, i_char, seq_lenght)** which takes a string, a **seq_length** number and a position.\n",
        "\n",
        "\n",
        "It should create X by by getting all character between i and i + seq_length\n",
        "and create y by getting the character following the X sequence\n",
        "it returns X and y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXHf-wYRF9Tb"
      },
      "source": [
        "Test your function on the following string \"\" with seq_length = 4 and i = [1, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKaTtQqdF9Tb",
        "outputId": "fbedd98f-75fd-466f-dd2c-fb1527fd0d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For i = 1: X = 'bcde', y = 'f'\n",
            "For i = 2: X = 'cdef', y = 'g'\n",
            "For i = 3: X = 'defg', y = 'h'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_X_and_y(string, i_char, seq_length):\n",
        "    \"\"\"\n",
        "    Builds input (X) and output (y) sequences for an LSTM model.\n",
        "\n",
        "    Args:\n",
        "        string: The input string.\n",
        "        i_char: The starting index for the sequence.\n",
        "        seq_length: The length of the input sequence.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the input sequence (X) and the corresponding output character (y).\n",
        "    \"\"\"\n",
        "    X = string[i_char:i_char + seq_length]\n",
        "    y = string[i_char + seq_length]\n",
        "    return X, y\n",
        "\n",
        "test_string = \"abcdefghij\"\n",
        "seq_length = 4\n",
        "indices = [1, 2, 3]\n",
        "\n",
        "for i in indices:\n",
        "    X, y = build_X_and_y(test_string, i, seq_length)\n",
        "    print(f\"For i = {i}: X = '{X}', y = '{y}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WXp5mKfF9Tb"
      },
      "source": [
        "By using build_X_and_y and map_char_to_int build a list nameed X_train and a list named y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "7mKMDAOMF9Tb"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "seq_length = 10\n",
        "\n",
        "char_to_int_map = map_char_to_int(distinct_chars)\n",
        "\n",
        "for molecule in df['smiles']:\n",
        "    for i in range(0, len(molecule) - seq_length, 1):\n",
        "        X, y = build_X_and_y(molecule, i, seq_length)\n",
        "        X_train.append([char_to_int_map[char] for char in X])\n",
        "        y_train.append(char_to_int_map[y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hUvksDWF9Tb"
      },
      "source": [
        "Create numpy arrays from the lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "n-ZmKWmpF9Tb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X6jcMCvKSfAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS2nNvk5SBnJ",
        "outputId": "cd207144-4f99-4147-b3ce-0a464bc1e290"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36242, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZcBKvxQF9Tb"
      },
      "source": [
        "Reshape the X numpy array (n_examples, seq_lenght, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36MLt53-F9Tb",
        "outputId": "27c26da5-240d-407c-d194-59df40736156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_train before is :  (36242, 10)\n",
            "Shape X_train after is :  (36242, 10, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape X_train before is : \",X_train.shape)\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], seq_length, 1)\n",
        "print(\"Shape X_train after is : \",X_train_reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oW5W9_bF9Tb"
      },
      "source": [
        "Normalize X by dividing each values by the total number of unic characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlgibC5DF9Tb",
        "outputId": "4a2f73c2-87d2-4cd0-d395-8b892ff8c9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36242, 10, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train_normalized = X_train_reshaped.astype('float32') / len(distinct_chars)\n",
        "print(X_train_normalized.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWB6s5vxF9Tb"
      },
      "source": [
        "Import Keras and build (at least) a two layered LSTM network with 128 neurone in each.\n",
        "\n",
        "You can also add Dropoutlayers\n",
        "\n",
        "Do you think you should use the return_sequences = True ? If yes, when ?\n",
        "\n",
        "\n",
        "Add a Dense layer on top with with the appropriate activation function and number of neurones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "wc6ELrGTF9Tf",
        "outputId": "65994253-ffe6-420d-a7e2-c9d9c6973454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m66,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)                  │           \u001b[38;5;34m4,257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,401\u001b[0m (790.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,401</span> (790.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,401\u001b[0m (790.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,401</span> (790.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(10, 1), return_sequences=True)) # return_sequences=True is needed because we have another LSTM layer after this one.\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128)) # return_sequences is False by default for the last LSTM layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(distinct_chars), activation='softmax')) # Output layer with softmax activation\n",
        "\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO2Dh66TF9Tf"
      },
      "source": [
        "Compile the model with the appropriate loss function and the adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "yKEuumRSF9Tf"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm8MYOsuF9Tf"
      },
      "source": [
        "Train the model on 20 epochs and 10 examples (yeah you read correctly) and\n",
        "\n",
        "---\n",
        "\n",
        "check that the model overfits !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtuYKGLnF9Tf",
        "outputId": "7f48ca1d-ca57-481e-9a10-4abbb26834e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3.3980\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.0805\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.8127\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.5409\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.2950\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.0552\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.7967\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8256\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7241\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.7927\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6245\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.4281\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.4644\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.6603\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.6404\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.5812\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.4165\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4210\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.3360\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.2938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4bcb89fd30>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "\n",
        "model.fit(X_train[:10], y_train[:10], epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjfoSsMLF9Tf"
      },
      "source": [
        "If it does not overfit try to fix data prep and model architecture so it does"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ybwYU-mmF9Tf"
      },
      "outputs": [],
      "source": [
        "#it did not overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXpr7UuKF9Tf"
      },
      "source": [
        "Create a function **make_prediction(seed_start)** which takes a starting string sequence and uses it to generate a molecule\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "D-BBV5C5F9Tf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_prediction(seed_start):\n",
        "    int_to_char_map = map_int_to_char(distinct_chars)\n",
        "    char_to_int_map = map_char_to_int(distinct_chars)\n",
        "    string_mapped = [char_to_int_map[char] for char in seed_start]\n",
        "    full_string = seed_start\n",
        "\n",
        "    for i in range(longest_length):\n",
        "        x = np.reshape(np.array(string_mapped), (1, len(string_mapped), 1))\n",
        "        x = x.astype('float32') / len(distinct_chars)\n",
        "        pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "        seq = int_to_char_map[pred_index]\n",
        "        full_string = full_string + seq\n",
        "        string_mapped.append(pred_index)\n",
        "        string_mapped = string_mapped[1:]\n",
        "        if seq == '\\n':\n",
        "            break\n",
        "    return full_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4M08y0nF9Tf"
      },
      "source": [
        "generate a molecule of your overfitted model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8js8yC5nF9Tf",
        "outputId": "039d230c-fa5a-4c3d-bf39-3f03217194dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(make_prediction(\"c\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXlaes8BF9Tf"
      },
      "source": [
        "Make a model checkpoint so that the model is saved after each epoch\n",
        "if you train on a plateform and it stops you do not lose your training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1soF_WwF9Tg",
        "outputId": "944be4df-87fa-4692-8c31-533e1f89f338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 1.2949\n",
            "Epoch 1: loss improved from inf to 1.29488, saving model to model_checkpoints/weights-improvement-01-1.2949.keras\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 1.2949\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3756\n",
            "Epoch 2: loss did not improve from 1.29488\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.3756\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3868\n",
            "Epoch 3: loss did not improve from 1.29488\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3868\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5746\n",
            "Epoch 4: loss did not improve from 1.29488\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5746\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3396\n",
            "Epoch 5: loss did not improve from 1.29488\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3396\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.3514\n",
            "Epoch 6: loss did not improve from 1.29488\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.3514\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.3032\n",
            "Epoch 7: loss did not improve from 1.29488\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.3032\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2327\n",
            "Epoch 8: loss improved from 1.29488 to 1.23269, saving model to model_checkpoints/weights-improvement-08-1.2327.keras\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.2327\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.4151\n",
            "Epoch 9: loss did not improve from 1.23269\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.4151\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2567\n",
            "Epoch 10: loss did not improve from 1.23269\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.2567\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.1986\n",
            "Epoch 11: loss improved from 1.23269 to 1.19858, saving model to model_checkpoints/weights-improvement-11-1.1986.keras\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.1986\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 1.1632\n",
            "Epoch 12: loss improved from 1.19858 to 1.16316, saving model to model_checkpoints/weights-improvement-12-1.1632.keras\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.1632\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2917\n",
            "Epoch 13: loss did not improve from 1.16316\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.2917\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2885\n",
            "Epoch 14: loss did not improve from 1.16316\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2885\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.2274\n",
            "Epoch 15: loss did not improve from 1.16316\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.2274\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1095\n",
            "Epoch 16: loss improved from 1.16316 to 1.10950, saving model to model_checkpoints/weights-improvement-16-1.1095.keras\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.1095\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.1504\n",
            "Epoch 17: loss did not improve from 1.10950\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 1.1504\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9817\n",
            "Epoch 18: loss improved from 1.10950 to 0.98169, saving model to model_checkpoints/weights-improvement-18-0.9817.keras\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9817\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.8270\n",
            "Epoch 19: loss improved from 0.98169 to 0.82703, saving model to model_checkpoints/weights-improvement-19-0.8270.keras\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8270\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9503\n",
            "Epoch 20: loss did not improve from 0.82703\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.9503\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4bce9cf820>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "# Define the filepath for model checkpoints\n",
        "filepath = \"model_checkpoints/weights-improvement-{epoch:02d}-{loss:.4f}.keras\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor='loss',  # Monitor the loss\n",
        "    verbose=1,\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode='min'  # Save when loss is minimized\n",
        ")\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model with the checkpoint callback\n",
        "model.fit(X_train[:10], y_train[:10], epochs=20, callbacks=[checkpoint])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE3VTQMeF9Tg"
      },
      "source": [
        "Now go to your favorite plateform (colab or something else) and train the dataset on the whole data for 10 epochs and batch size 256\n",
        "\n",
        "it should take a long time so either follow the class or go take a nap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Check for NaN values in X_train\n",
        "nan_in_X = np.isnan(X_train).any()\n",
        "if nan_in_X:\n",
        "    print(\"X_train contains NaN values.\")\n",
        "\n",
        "# Check for NaN values in y_train\n",
        "nan_in_y = np.isnan(y_train).any()\n",
        "if nan_in_y:\n",
        "    print(\"y_train contains NaN values.\")\n",
        "    # Handle NaN values in y_train if necessary\n",
        "\n",
        "# Check for infinite values in X_train\n",
        "inf_in_X = np.isinf(X_train).any()\n",
        "if inf_in_X:\n",
        "    print(\"X_train contains infinite values.\")\n",
        "    # Handle infinite values in X_train if necessary\n",
        "\n",
        "# Check for infinite values in y_train\n",
        "inf_in_y = np.isinf(y_train).any()\n",
        "if inf_in_y:\n",
        "    print(\"y_train contains infinite values.\")\n",
        "    # Handle infinite values in y_train if necessary\n",
        "\n",
        "# Additional checks (if needed)\n",
        "# Check data types, shapes, ranges, etc.\n",
        "\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzZOF-OQQEBl",
        "outputId": "2479392d-c16a-4a14-c59d-7ab3364e0414"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type of X_train: int64\n",
            "Data type of y_train: int64\n",
            "Shape of X_train: (36242, 10)\n",
            "Shape of y_train: (36242,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew0FoXwDF9Tg",
        "outputId": "a3be4f6e-7a3b-4110-a897-75227bc01cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m125/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1814 - loss: 2.9490\n",
            "Epoch 1: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1816 - loss: 2.9437 - val_accuracy: 0.1686 - val_loss: 2.7209\n",
            "Epoch 2/10\n",
            "\u001b[1m121/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1956 - loss: 2.6875\n",
            "Epoch 2: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1955 - loss: 2.6879 - val_accuracy: 0.1975 - val_loss: 2.7006\n",
            "Epoch 3/10\n",
            "\u001b[1m126/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2019 - loss: 2.6743\n",
            "Epoch 3: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2019 - loss: 2.6741 - val_accuracy: 0.1848 - val_loss: 2.6461\n",
            "Epoch 4/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2159 - loss: 2.6019\n",
            "Epoch 4: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2159 - loss: 2.6017 - val_accuracy: 0.2472 - val_loss: 2.5065\n",
            "Epoch 5/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2463 - loss: 2.4701\n",
            "Epoch 5: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2463 - loss: 2.4698 - val_accuracy: 0.2477 - val_loss: 2.4240\n",
            "Epoch 6/10\n",
            "\u001b[1m126/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2779 - loss: 2.3579\n",
            "Epoch 6: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2782 - loss: 2.3571 - val_accuracy: 0.2996 - val_loss: 2.2662\n",
            "Epoch 7/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3308 - loss: 2.2003\n",
            "Epoch 7: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3309 - loss: 2.2001 - val_accuracy: 0.3608 - val_loss: 2.1207\n",
            "Epoch 8/10\n",
            "\u001b[1m124/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3657 - loss: 2.0839\n",
            "Epoch 8: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3662 - loss: 2.0828 - val_accuracy: 0.3926 - val_loss: 2.0128\n",
            "Epoch 9/10\n",
            "\u001b[1m126/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4012 - loss: 1.9724\n",
            "Epoch 9: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4014 - loss: 1.9720 - val_accuracy: 0.4221 - val_loss: 1.9233\n",
            "Epoch 10/10\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4385 - loss: 1.8747\n",
            "Epoch 10: loss did not improve from 0.82703\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4385 - loss: 1.8747 - val_accuracy: 0.4428 - val_loss: 1.8430\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=34)  # 34 classes\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(X_train_normalized.shape[1], 1)),\n",
        "    LSTM(64),\n",
        "    Dense(34, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_normalized, y_train_encoded,\n",
        "                    epochs=10,\n",
        "                    batch_size=256,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0dqh1M8F9Tg"
      },
      "source": [
        "Generate between 100 and 1000 molecules.\n",
        "\n",
        "create a list where molecules have between 10 and 50 atoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmQw5tYBF9Tg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to generate multiple molecules\n",
        "def generate_molecules(num_molecules=1000, min_atoms=10, max_atoms=50):\n",
        "    generated_molecules = []\n",
        "\n",
        "    while len(generated_molecules) < num_molecules:\n",
        "        seed = \"CC\"  # Starting seed\n",
        "        molecule = make_prediction(seed)\n",
        "\n",
        "        # Check if molecule length (excluding padding) is within the desired range\n",
        "        if min_atoms <= len(molecule.strip()) <= max_atoms:\n",
        "            generated_molecules.append(molecule.strip())  # Remove padding and add to the list\n",
        "\n",
        "    return generated_molecules\n",
        "\n",
        "# Generate molecules\n",
        "molecules = generate_molecules(1000, 10, 50)\n",
        "\n",
        "# Output the number of molecules generated\n",
        "print(f\"Total molecules generated: {len(molecules)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAreozOQF9Tg"
      },
      "source": [
        "[texte du lien](https://)With rdkit compute the Quantified Estimated Drug likelyness (QED) of each molecule in this subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZBh19VIF9Tg"
      },
      "outputs": [],
      "source": [
        "def compute_qed(molecules):\n",
        "    qed_values = []\n",
        "\n",
        "    for mol in molecules:\n",
        "        # Convert the SMILES string to an RDKit molecule object\n",
        "        mol_obj = Chem.MolFromSmiles(mol)\n",
        "        if mol_obj is not None:\n",
        "            # Compute the QED\n",
        "            qed = QED.qed(mol_obj)\n",
        "            qed_values.append(qed)\n",
        "        else:\n",
        "            qed_values.append(None)  # If molecule is invalid or cannot be processed, return None\n",
        "\n",
        "    return qed_values\n",
        "\n",
        "molecules = generate_molecules(1000, 10, 50)\n",
        "\n",
        "qed_values = compute_qed(molecules)\n",
        "\n",
        "print(f\"Total molecules generated: {len(molecules)}\")\n",
        "print(f\"QED values computed: {len(qed_values)}\")\n",
        "print(f\"Mean QED: {np.mean([q for q in qed_values if q is not None]):.3f}\")\n",
        "print(f\"Median QED: {np.median([q for q in qed_values if q is not None]):.3f}\")\n",
        "print(f\"Number of molecules with valid QED values: {len([q for q in qed_values if q is not None])}\")\n",
        "\n",
        "# Optionally, print some QED values for inspection\n",
        "print(\"Sample QED values:\")\n",
        "for mol, qed in zip(molecules[:10], qed_values[:10]):\n",
        "    print(f\"Molecule: {mol[:30]}... QED: {qed:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iETtg7iF9Tg"
      },
      "source": [
        "Bonus 1 : Using rdkit, compute the quantitative estimation of drug-likeness (QED) of your generated molecules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHvru05lF9Tg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hxM4qutF9Tg"
      },
      "source": [
        "Bonus 2 : try to adapt a transformer model training from hugging face to see if it is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9EL0OECF9Tg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}